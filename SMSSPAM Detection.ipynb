{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60350401",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31b5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing all the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import seaborn as sns\n",
    "import re  # search pattern in string ( text) \n",
    "import nltk # nlp \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ccfde",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d668ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"D:\\ML PROJECT\\spam.csv\",encoding='latin-1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d15ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping unwanted columns\n",
    "data = data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
    "\n",
    "#Naming the columns\n",
    "data = data.rename(columns = {'v1':'label','v2':'message'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c5952",
   "metadata": {},
   "source": [
    "# Checking Shape of The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c6a125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93436f",
   "metadata": {},
   "source": [
    "# Taking Single Column For The Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01eb3219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Wait that's still not all that clear, were you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Yeah he got in at 2 and was v apologetic. n ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>K tell me anything about you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>For fear of fainting with the of all that hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Thanks for your subscription to Ringtone UK yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message\n",
       "0   Go until jurong point, crazy.. Available only ...\n",
       "1                       Ok lar... Joking wif u oni...\n",
       "2   Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   U dun say so early hor... U c already then say...\n",
       "4   Nah I don't think he goes to usf, he lives aro...\n",
       "5   FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   Even my brother is not like to speak with me. ...\n",
       "7   As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   WINNER!! As a valued network customer you have...\n",
       "9   Had your mobile 11 months or more? U R entitle...\n",
       "10  I'm gonna be home soon and i don't want to tal...\n",
       "11  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12  URGENT! You have won a 1 week FREE membership ...\n",
       "13  I've been searching for the right words to tha...\n",
       "14                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15  XXXMobileMovieClub: To use your credit, click ...\n",
       "16                         Oh k...i'm watching here:)\n",
       "17  Eh u remember how 2 spell his name... Yes i di...\n",
       "18  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
       "19  England v Macedonia - dont miss the goals/team...\n",
       "20          Is that seriously how you spell his name?\n",
       "21  IÛ÷m going to try for 2 months ha ha only joking\n",
       "22  So Ì_ pay first lar... Then when is da stock c...\n",
       "23  Aft i finish my lunch then i go str down lor. ...\n",
       "24  Ffffffffff. Alright no way I can meet up with ...\n",
       "25  Just forced myself to eat a slice. I'm really ...\n",
       "26                     Lol your always so convincing.\n",
       "27  Did you catch the bus ? Are you frying an egg ...\n",
       "28  I'm back &amp; we're packing the car now, I'll...\n",
       "29  Ahhh. Work. I vaguely remember that! What does...\n",
       "30  Wait that's still not all that clear, were you...\n",
       "31  Yeah he got in at 2 and was v apologetic. n ha...\n",
       "32                      K tell me anything about you.\n",
       "33  For fear of fainting with the of all that hous...\n",
       "34  Thanks for your subscription to Ringtone UK yo..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data[['message']]\n",
    "df.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecbe59b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d0e47",
   "metadata": {},
   "source": [
    "# Converted to Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d5208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.message=df.message.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c7eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005. text fa to 87121 to receive entry question(std txt rate)t&c's apply 08452810075over18's\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db11de",
   "metadata": {},
   "source": [
    "# Removing Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac9c455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxxmobilemovieclub: to use your credit, click the wap link in the next txt message or click here>>  xxxmobilemovieclub.com?n=qjkgighjjgcbl'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.message = df.message.str.replace(r'http://wap.','',case=False)\n",
    "df.iloc[15,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c3edc",
   "metadata": {},
   "source": [
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa65815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50a4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(abc):\n",
    "    text_nopunt=\"\".join([c  # c= delhi\n",
    "                         for c in abc # c = Delhi \n",
    "                         if c not in string.punctuation])\n",
    "    return text_nopunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a28a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.message=df.message.apply(lambda x : remove_punctuation(x)) # Text = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b245c8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "288341ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74c285",
   "metadata": {},
   "source": [
    "# Remove Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7321c4fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d5541",
   "metadata": {},
   "source": [
    "* \\d == Returns a match where the string contains digits (numbers from 0-9)\n",
    "* (+) == one or more occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "457b3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.message = df.message.str.replace('\\d+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eea0c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry in  a wkly comp to win fa cup final tkts st may  text fa to  to receive entry questionstd txt ratetcs apply overs'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa439e",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b04ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8646e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stopwords with nltk.\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d934fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7284a9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry in  a wkly comp to win fa cup final tkts st may  text fa to  to receive entry questionstd txt ratetcs apply overs'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8ada34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "df.message = df.message.apply(lambda x: ' '.join([c   # form  is not added   # text = x\n",
    "                                                      for c in x.split()  # c = from\n",
    "                                                      if c not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff7ca617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry wkly comp win fa cup final tkts st may text fa receive entry questionstd txt ratetcs apply overs'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8626610",
   "metadata": {},
   "source": [
    "# Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce245aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aliform',\n",
       " 'deadwood',\n",
       " 'electrodialyzer',\n",
       " 'vire',\n",
       " 'abiotrophy',\n",
       " 'opisthocome',\n",
       " 'hailshot',\n",
       " 'crotin',\n",
       " 'unsophisticatedly',\n",
       " 'naveled',\n",
       " 'chay',\n",
       " 'nonperformance',\n",
       " 'brachyure',\n",
       " 'homiletical',\n",
       " 'prefiguration',\n",
       " 'rotulus',\n",
       " 'tenantableness',\n",
       " 'diphtherian',\n",
       " 'hydramine',\n",
       " 'exsibilation',\n",
       " 'heptadecyl',\n",
       " 'chloroplatinite',\n",
       " 'premillennial',\n",
       " 'hawbuck',\n",
       " 'characterizable',\n",
       " 'gasworker',\n",
       " 'markdown',\n",
       " 'bothersome',\n",
       " 'switchback',\n",
       " 'parsonhood',\n",
       " 'poetastery',\n",
       " 'Shakespearize',\n",
       " 'territorial',\n",
       " 'kirklike',\n",
       " 'unflagitious',\n",
       " 'unstablished',\n",
       " 'Proctotrypoidea',\n",
       " 'shareholdership',\n",
       " 'lissencephalic',\n",
       " 'obsequent',\n",
       " 'propylamine',\n",
       " 'unhurriedly',\n",
       " 'reassemble',\n",
       " 'Raul',\n",
       " 'planigraph',\n",
       " 'unshapeliness',\n",
       " 'anticrisis',\n",
       " 'pneumographic',\n",
       " 'archmagician',\n",
       " 'pleurovisceral',\n",
       " 'patterer',\n",
       " 'conceptualization',\n",
       " 'unmotivated',\n",
       " 'outvoyage',\n",
       " 'spectrophotometry',\n",
       " 'unsecret',\n",
       " 'widowman',\n",
       " 'sleighing',\n",
       " 'pulpiteer',\n",
       " 'mensa',\n",
       " 'juggling',\n",
       " 'downness',\n",
       " 'conjugate',\n",
       " 'ilot',\n",
       " 'plumieride',\n",
       " 'boomorah',\n",
       " 'unlooped',\n",
       " 'feretrum',\n",
       " 'titien',\n",
       " 'biangulated',\n",
       " 'honorance',\n",
       " 'hypognathism',\n",
       " 'perorator',\n",
       " 'undeducted',\n",
       " 'bakeoven',\n",
       " 'amorousness',\n",
       " 'phellonic',\n",
       " 'Doricize',\n",
       " 'foremother',\n",
       " 'squamosity',\n",
       " 'erelong',\n",
       " 'primigenian',\n",
       " 'paristhmion',\n",
       " 'limnobiological',\n",
       " 'electrorefine',\n",
       " 'plenilune',\n",
       " 'retrocede',\n",
       " 'savoy',\n",
       " 'rejective',\n",
       " 'squatterproof',\n",
       " 'basisphenoid',\n",
       " 'victualing',\n",
       " 'navigerous',\n",
       " 'theotechnist',\n",
       " 'oligophosphaturia',\n",
       " 'vetitive',\n",
       " 'burin',\n",
       " 'charitableness',\n",
       " 'verdoy',\n",
       " 'laconically',\n",
       " 'Tsuma',\n",
       " 'Amritsar',\n",
       " 'tarsomalacia',\n",
       " 'youl',\n",
       " 'Prudence',\n",
       " 'impersuadable',\n",
       " 'preaccumulate',\n",
       " 'contrastimulation',\n",
       " 'cytopathologically',\n",
       " 'chortle',\n",
       " 'decurrently',\n",
       " 'doubleted',\n",
       " 'Mandalay',\n",
       " 'dissyllabize',\n",
       " 'paleoanthropological',\n",
       " 'polarizer',\n",
       " 'pontooner',\n",
       " 'to',\n",
       " 'rod',\n",
       " 'bootmaking',\n",
       " 'charlatanry',\n",
       " 'dicaryophase',\n",
       " 'wheedling',\n",
       " 'sudatory',\n",
       " 'bussu',\n",
       " 'tripterous',\n",
       " 'Negroid',\n",
       " 'backgame',\n",
       " 'pants',\n",
       " 'monocondylian',\n",
       " 'ombrograph',\n",
       " 'lyencephalous',\n",
       " 'ripener',\n",
       " 'nudger',\n",
       " 'Maskins',\n",
       " 'makuk',\n",
       " 'pailou',\n",
       " 'zoril',\n",
       " 'pluricuspidate',\n",
       " 'ultimogenitary',\n",
       " 'unsqueezable',\n",
       " 'spicing',\n",
       " 'uteroplasty',\n",
       " 'anoxic',\n",
       " 'cripes',\n",
       " 'scree',\n",
       " 'raise',\n",
       " 'nonexemplary',\n",
       " 'Julian',\n",
       " 'levator',\n",
       " 'desensitizer',\n",
       " 'Corallina',\n",
       " 'guardfully',\n",
       " 'intermomentary',\n",
       " 'chamiso',\n",
       " 'aloud',\n",
       " 'Hortense',\n",
       " 'proinnovationist',\n",
       " 'witwall',\n",
       " 'versicolorate',\n",
       " 'alienor',\n",
       " 'unmalleableness',\n",
       " 'reconcert',\n",
       " 'blustering',\n",
       " 'misreflect',\n",
       " 'sesquisalt',\n",
       " 'spumescent',\n",
       " 'alveolite',\n",
       " 'loadage',\n",
       " 'lumberdom',\n",
       " 'unguard',\n",
       " 'skimp',\n",
       " 'twelvepenny',\n",
       " 'monoclinally',\n",
       " 'squireocracy',\n",
       " 'geocronite',\n",
       " 'plutonomy',\n",
       " 'sesquiplicate',\n",
       " 'accordance',\n",
       " 'candlelighting',\n",
       " 'contraposita',\n",
       " 'everyhow',\n",
       " 'flurr',\n",
       " 'melatope',\n",
       " 'excathedral',\n",
       " 'frithborh',\n",
       " 'primogenitary',\n",
       " 'nonrestraint',\n",
       " 'Geoff',\n",
       " 'nonnitrogenous',\n",
       " 'brazilein',\n",
       " 'cytasic',\n",
       " 'heaving',\n",
       " 'Anglican',\n",
       " 'hollin',\n",
       " 'winterliness',\n",
       " 'ihleite',\n",
       " 'urgently',\n",
       " 'tapiridian',\n",
       " 'Baramika',\n",
       " 'assent',\n",
       " 'browsing',\n",
       " 'uninterruptedness',\n",
       " 'Vertebrata',\n",
       " 'imperishable',\n",
       " 'invigorative',\n",
       " 'hockshin',\n",
       " 'indumentum',\n",
       " 'Rachiglossa',\n",
       " 'unaggravating',\n",
       " 'unequiaxed',\n",
       " 'unwintry',\n",
       " 'rovet',\n",
       " 'Jerahmeelites',\n",
       " 'ensignhood',\n",
       " 'copresent',\n",
       " 'Theaceae',\n",
       " 'corporas',\n",
       " 'adversifolious',\n",
       " 'atomistics',\n",
       " 'steerage',\n",
       " 'Cara',\n",
       " 'lakemanship',\n",
       " 'dime',\n",
       " 'indiscernibility',\n",
       " 'milkshop',\n",
       " 'Scian',\n",
       " 'continuateness',\n",
       " 'susceptor',\n",
       " 'hydroptic',\n",
       " 'bald',\n",
       " 'allothogenic',\n",
       " 'scullionize',\n",
       " 'cacodaemonic',\n",
       " 'inhabitedness',\n",
       " 'cataleptiform',\n",
       " 'offish',\n",
       " 'proofread',\n",
       " 'boryl',\n",
       " 'platyglossate',\n",
       " 'prenatally',\n",
       " 'rokee',\n",
       " 'nauseant',\n",
       " 'rockaway',\n",
       " 'inobedient',\n",
       " 'fairish',\n",
       " 'Buriat',\n",
       " 'Noachical',\n",
       " 'celioschisis',\n",
       " 'unimprovably',\n",
       " 'pseudoarthrosis',\n",
       " 'homelet',\n",
       " 'corruptibility',\n",
       " 'Johan',\n",
       " 'abthainrie',\n",
       " 'anthracia',\n",
       " 'unremuneratively',\n",
       " 'undisgorged',\n",
       " 'Bertolonia',\n",
       " 'clupanodonic',\n",
       " 'autospore',\n",
       " 'privileged',\n",
       " 'overremissness',\n",
       " 'alfaje',\n",
       " 'demerit',\n",
       " 'saprophytism',\n",
       " 'unexcusing',\n",
       " 'glycogen',\n",
       " 'squeezer',\n",
       " 'torulus',\n",
       " 'huggle',\n",
       " 'inexplorable',\n",
       " 'unengaging',\n",
       " 'impunctuality',\n",
       " 'Slovenian',\n",
       " 'veldschoen',\n",
       " 'Cheltenham',\n",
       " 'kittenhood',\n",
       " 'imperceptive',\n",
       " 'habitant',\n",
       " 'wrothiness',\n",
       " 'hyphomycosis',\n",
       " 'remuneration',\n",
       " 'homeland',\n",
       " 'andante',\n",
       " 'castigative',\n",
       " 'aureomycin',\n",
       " 'educational',\n",
       " 'asseveration',\n",
       " 'colonnaded',\n",
       " 'megaloblast',\n",
       " 'wifehood',\n",
       " 'monstrousness',\n",
       " 'alicoche',\n",
       " 'snareless',\n",
       " 'Zulhijjah',\n",
       " 'Heteromeran',\n",
       " 'nonteacher',\n",
       " 'statutably',\n",
       " 'fredricite',\n",
       " 'trifuran',\n",
       " 'redeveloper',\n",
       " 'yak',\n",
       " 'stipendiate',\n",
       " 'septship',\n",
       " 'envermeil',\n",
       " 'ureterosalpingostomy',\n",
       " 'managee',\n",
       " 'uncivilizedness',\n",
       " 'tablemaker',\n",
       " 'acetabular',\n",
       " 'dangerousness',\n",
       " 'saintliness',\n",
       " 'strue',\n",
       " 'iserite',\n",
       " 'broken',\n",
       " 'Celluloid',\n",
       " 'Itali',\n",
       " 'lillibullero',\n",
       " 'peotomy',\n",
       " 'wakiki',\n",
       " 'potgirl',\n",
       " 'overbowed',\n",
       " 'enclosure',\n",
       " 'imprest',\n",
       " 'achlamydate',\n",
       " 'amyotrophy',\n",
       " 'falsificator',\n",
       " 'minatorially',\n",
       " 'trichoma',\n",
       " 'ostreicultural',\n",
       " 'semimachine',\n",
       " 'phytic',\n",
       " 'ethnicize',\n",
       " 'skilled',\n",
       " 'uncargoed',\n",
       " 'scientolism',\n",
       " 'coeruleolactite',\n",
       " 'unstaled',\n",
       " 'envy',\n",
       " 'Ceratophrys',\n",
       " 'noncontroversial',\n",
       " 'steelware',\n",
       " 'dishabilitate',\n",
       " 'unflowing',\n",
       " 'mastadenitis',\n",
       " 'curtainless',\n",
       " 'gib',\n",
       " 'byegaein',\n",
       " 'interruptedness',\n",
       " 'scaffle',\n",
       " 'papillose',\n",
       " 'gustless',\n",
       " 'graceful',\n",
       " 'hygromatous',\n",
       " 'underlease',\n",
       " 'dunlin',\n",
       " 'Spheniscus',\n",
       " 'punctualness',\n",
       " 'irresistance',\n",
       " 'snowhammer',\n",
       " 'Theophania',\n",
       " 'Cnidoscolus',\n",
       " 'chuff',\n",
       " 'dawnstreak',\n",
       " 'thrillingness',\n",
       " 'anisomelia',\n",
       " 'Deimos',\n",
       " 'didelphous',\n",
       " 'monarchical',\n",
       " 'crithmene',\n",
       " 'owler',\n",
       " 'realtor',\n",
       " 'symphogenous',\n",
       " 'murgavi',\n",
       " 'methylacetanilide',\n",
       " 'riddance',\n",
       " 'nucleiform',\n",
       " 'rohan',\n",
       " 'unrisen',\n",
       " 'eaglet',\n",
       " 'preinsure',\n",
       " 'insinuation',\n",
       " 'heptose',\n",
       " 'tarriness',\n",
       " 'scauper',\n",
       " 'feuilletonism',\n",
       " 'unfeted',\n",
       " 'Solomonic',\n",
       " 'guy',\n",
       " 'clerkdom',\n",
       " 'flowering',\n",
       " 'lazule',\n",
       " 'afterchurch',\n",
       " 'unbeatableness',\n",
       " 'arboriform',\n",
       " 'ferash',\n",
       " 'pararosaniline',\n",
       " 'terramare',\n",
       " 'nonya',\n",
       " 'pueblito',\n",
       " 'Thunbergia',\n",
       " 'kommetje',\n",
       " 'providentially',\n",
       " 'unscrupulously',\n",
       " 'hoplitic',\n",
       " 'autographometer',\n",
       " 'Esth',\n",
       " 'indirect',\n",
       " 'thickhead',\n",
       " 'Sirenoidei',\n",
       " 'showerer',\n",
       " 'expressively',\n",
       " 'windlessness',\n",
       " 'zabtie',\n",
       " 'papion',\n",
       " 'hyperosmia',\n",
       " 'gobbledygook',\n",
       " 'cormophytic',\n",
       " 'iridescently',\n",
       " 'Everett',\n",
       " 'photobiotic',\n",
       " 'feces',\n",
       " 'Prioninae',\n",
       " 'gamely',\n",
       " 'jubilize',\n",
       " 'jawfallen',\n",
       " 'mistresshood',\n",
       " 'categorematic',\n",
       " 'recommunicate',\n",
       " 'nonconsignment',\n",
       " 'whimsically',\n",
       " 'welting',\n",
       " 'lepidopterology',\n",
       " 'Phomopsis',\n",
       " 'crawful',\n",
       " 'palatoplasty',\n",
       " 'raku',\n",
       " 'slumberproof',\n",
       " 'insigne',\n",
       " 'outworn',\n",
       " 'armiger',\n",
       " 'picnicky',\n",
       " 'bootery',\n",
       " 'unelemental',\n",
       " 'unrebuffable',\n",
       " 'Vermont',\n",
       " 'murderment',\n",
       " 'fishless',\n",
       " 'anatomy',\n",
       " 'baccivorous',\n",
       " 'reekingly',\n",
       " 'anticrochet',\n",
       " 'multivalent',\n",
       " 'Senusism',\n",
       " 'prankful',\n",
       " 'rainlessness',\n",
       " 'erosional',\n",
       " 'swarm',\n",
       " 'wagwants',\n",
       " 'Bolognese',\n",
       " 'Sarraceniaceae',\n",
       " 'Megalonychidae',\n",
       " 'wairch',\n",
       " 'pectoralist',\n",
       " 'outsophisticate',\n",
       " 'stamin',\n",
       " 'overtoise',\n",
       " 'nitrolamine',\n",
       " 'age',\n",
       " 'gelandelaufer',\n",
       " 'optic',\n",
       " 'polyaxon',\n",
       " 'Takhaar',\n",
       " 'unalcoholized',\n",
       " 'blur',\n",
       " 'lawnlike',\n",
       " 'myopical',\n",
       " 'fibrose',\n",
       " 'subterpose',\n",
       " 'Prosopis',\n",
       " 'fiberboard',\n",
       " 'uninterpolated',\n",
       " 'organizational',\n",
       " 'homoblasty',\n",
       " 'poisonable',\n",
       " 'wet',\n",
       " 'detachably',\n",
       " 'farawayness',\n",
       " 'supramammary',\n",
       " 'whincheck',\n",
       " 'undercause',\n",
       " 'Austrian',\n",
       " 'agalactic',\n",
       " 'attacher',\n",
       " 'quarterization',\n",
       " 'ennerve',\n",
       " 'primly',\n",
       " 'cuff',\n",
       " 'pylethrombophlebitis',\n",
       " 'subventive',\n",
       " 'nonjuristic',\n",
       " 'calycophoran',\n",
       " 'perambulate',\n",
       " 'lache',\n",
       " 'bilinear',\n",
       " 'unfunnily',\n",
       " 'Delphinidae',\n",
       " 'entoptoscopy',\n",
       " 'mutteringly',\n",
       " 'nonvariant',\n",
       " 'tartaric',\n",
       " 'schizogony',\n",
       " 'unfainting',\n",
       " 'follicular',\n",
       " 'electrography',\n",
       " 'myliobatine',\n",
       " 'irenicism',\n",
       " 'parotiditis',\n",
       " 'tetartosymmetry',\n",
       " 'uneagerness',\n",
       " 'overweening',\n",
       " 'spreadover',\n",
       " 'disintegrate',\n",
       " 'incitation',\n",
       " 'Spigeliaceae',\n",
       " 'physiographically',\n",
       " 'aftercourse',\n",
       " 'nonconfinement',\n",
       " 'landspout',\n",
       " 'taperly',\n",
       " 'promonarchist',\n",
       " 'actinopteran',\n",
       " 'sparrowy',\n",
       " 'Ronsardist',\n",
       " 'Jan',\n",
       " 'labefactation',\n",
       " 'leucopyrite',\n",
       " 'serousness',\n",
       " 'adder',\n",
       " 'heterogeneously',\n",
       " 'Erwin',\n",
       " 'tiderace',\n",
       " 'Cajanus',\n",
       " 'formonitrile',\n",
       " 'shelterer',\n",
       " 'torchwort',\n",
       " 'aumildar',\n",
       " 'hydroxyanthraquinone',\n",
       " 'afterbreach',\n",
       " 'illimitedness',\n",
       " 'javelineer',\n",
       " 'alkalinization',\n",
       " 'quinogen',\n",
       " 'sensationalize',\n",
       " 'phylloxanthin',\n",
       " 'fady',\n",
       " 'unheedy',\n",
       " 'suld',\n",
       " 'Atremata',\n",
       " 'retractible',\n",
       " 'Irvingesque',\n",
       " 'porporate',\n",
       " 'contrariety',\n",
       " 'acrogynous',\n",
       " 'trimetrical',\n",
       " 'breva',\n",
       " 'circumnuclear',\n",
       " 'endoplastron',\n",
       " 'hemicatalepsy',\n",
       " 'Gelasian',\n",
       " 'sonometer',\n",
       " 'toruloid',\n",
       " 'tonsor',\n",
       " 'undiminishably',\n",
       " 'withdraught',\n",
       " 'antifeminism',\n",
       " 'unschooledness',\n",
       " 'besodden',\n",
       " 'proprietor',\n",
       " 'gastroptosia',\n",
       " 'Jeanie',\n",
       " 'miscreate',\n",
       " 'Smilax',\n",
       " 'Blemmyes',\n",
       " 'brainge',\n",
       " 'maladive',\n",
       " 'electrogalvanize',\n",
       " 'ructation',\n",
       " 'archibenthic',\n",
       " 'Cycliae',\n",
       " 'mancipate',\n",
       " 'Ismailian',\n",
       " 'muscariform',\n",
       " 'bushlike',\n",
       " 'undebating',\n",
       " 'psychiatria',\n",
       " 'lempira',\n",
       " 'Agathosma',\n",
       " 'choledocholithotripsy',\n",
       " 'atreptic',\n",
       " 'torturesome',\n",
       " 'Mincopi',\n",
       " 'unadvisableness',\n",
       " 'arachnoid',\n",
       " 'misrepeat',\n",
       " 'outsuck',\n",
       " 'yttrocolumbite',\n",
       " 'Herculanensian',\n",
       " 'trittichan',\n",
       " 'Taltushtuntude',\n",
       " 'architraved',\n",
       " 'litigiosity',\n",
       " 'Camellus',\n",
       " 'sierra',\n",
       " 'interpilastering',\n",
       " 'empiecement',\n",
       " 'earwort',\n",
       " 'gutless',\n",
       " 'wudge',\n",
       " 'pachyglossal',\n",
       " 'cynomoriaceous',\n",
       " 'solum',\n",
       " 'lenth',\n",
       " 'labor',\n",
       " 'exosperm',\n",
       " 'Senijextee',\n",
       " 'insubordinate',\n",
       " 'spectroscopy',\n",
       " 'spinulous',\n",
       " 'stolonlike',\n",
       " 'misauthorize',\n",
       " 'volutoid',\n",
       " 'Arabis',\n",
       " 'sextarius',\n",
       " 'unsaid',\n",
       " 'alkalimetrically',\n",
       " 'undermaker',\n",
       " 'Branchiopulmonata',\n",
       " 'unsinewing',\n",
       " 'thermosynthesis',\n",
       " 'billbroking',\n",
       " 'photoanamorphosis',\n",
       " 'hydrocarbon',\n",
       " 'miscipher',\n",
       " 'subprioress',\n",
       " 'anoxemic',\n",
       " 'osteolysis',\n",
       " 'restionaceous',\n",
       " 'supralineal',\n",
       " 'portability',\n",
       " 'exhibitively',\n",
       " 'bidactyl',\n",
       " 'steading',\n",
       " 'ciclatoun',\n",
       " 'lichenism',\n",
       " 'inadventurous',\n",
       " 'uncomposed',\n",
       " 'gynecologic',\n",
       " 'overmellow',\n",
       " 'glossophorous',\n",
       " 'unclogged',\n",
       " 'Protephemeroidea',\n",
       " 'Larvalia',\n",
       " 'unintoned',\n",
       " 'bisglyoxaline',\n",
       " 'Forst',\n",
       " 'impersonable',\n",
       " 'neutroceptor',\n",
       " 'disdiaclast',\n",
       " 'resubstitute',\n",
       " 'bistro',\n",
       " 'entach',\n",
       " 'Hesychasm',\n",
       " 'salting',\n",
       " 'thickset',\n",
       " 'cenobian',\n",
       " 'cambism',\n",
       " 'Prunella',\n",
       " 'bibliology',\n",
       " 'abelite',\n",
       " 'chirpingly',\n",
       " 'rhetoricalness',\n",
       " 'jadishly',\n",
       " 'twitten',\n",
       " 'closehearted',\n",
       " 'Grapsus',\n",
       " 'ripa',\n",
       " 'Batetela',\n",
       " 'outpension',\n",
       " 'oafishness',\n",
       " 'hypophalangism',\n",
       " 'nonfamily',\n",
       " 'executable',\n",
       " 'concoagulate',\n",
       " 'endocorpuscular',\n",
       " 'goblinry',\n",
       " 'slop',\n",
       " 'sulphurproof',\n",
       " 'prorrhesis',\n",
       " 'gasproof',\n",
       " 'hemolymphatic',\n",
       " 'reappointment',\n",
       " 'hammerbird',\n",
       " 'treasonful',\n",
       " 'porphyry',\n",
       " 'encrotchet',\n",
       " 'firetop',\n",
       " 'sunbonneted',\n",
       " 'Alocasia',\n",
       " 'monoacidic',\n",
       " 'presumedly',\n",
       " 'unbench',\n",
       " 'discastle',\n",
       " 'nontillable',\n",
       " 'Marsian',\n",
       " 'methodist',\n",
       " 'tupman',\n",
       " 'connectible',\n",
       " 'propination',\n",
       " 'aparaphysate',\n",
       " 'busyish',\n",
       " 'monticellite',\n",
       " 'platosammine',\n",
       " 'wahahe',\n",
       " 'detax',\n",
       " 'tweezer',\n",
       " 'telelectroscope',\n",
       " 'rectilineally',\n",
       " 'denty',\n",
       " 'nonsolid',\n",
       " 'Brendan',\n",
       " 'quadrupedous',\n",
       " 'fendy',\n",
       " 'catogene',\n",
       " 'quave',\n",
       " 'conflagrative',\n",
       " 'annonaceous',\n",
       " 'mandibulomaxillary',\n",
       " 'hemihedric',\n",
       " 'Danielic',\n",
       " 'azurite',\n",
       " 'tympanomastoid',\n",
       " 'tuppence',\n",
       " 'impinge',\n",
       " 'acrobatics',\n",
       " 'reflood',\n",
       " 'neogrammatical',\n",
       " 'quadrifarious',\n",
       " 'allegorist',\n",
       " 'forebreast',\n",
       " 'slipperyback',\n",
       " 'Bobbinite',\n",
       " 'dolichopodous',\n",
       " 'cremnophobia',\n",
       " 'nauplioid',\n",
       " 'roundly',\n",
       " 'ungallantly',\n",
       " 'Primianist',\n",
       " 'cephid',\n",
       " 'transformistic',\n",
       " 'pantagruelion',\n",
       " 'melanilin',\n",
       " 'bemoon',\n",
       " 'emblic',\n",
       " 'steelproof',\n",
       " 'hairsplitter',\n",
       " 'caber',\n",
       " 'griller',\n",
       " 'unsesquipedalian',\n",
       " 'berkovets',\n",
       " 'rehabilitation',\n",
       " 'menaccanitic',\n",
       " 'bibliotherapeutic',\n",
       " 'Isidoric',\n",
       " 'parachrome',\n",
       " 'batlike',\n",
       " 'poppean',\n",
       " 'tram',\n",
       " 'uninfiltrated',\n",
       " 'connexionalism',\n",
       " 'Mixtec',\n",
       " 'adolescent',\n",
       " 'carpogam',\n",
       " 'psychrometrical',\n",
       " 'gerhardtite',\n",
       " 'Cirrhopetalum',\n",
       " 'downfolded',\n",
       " 'chaise',\n",
       " 'glycidol',\n",
       " 'nitrocalcite',\n",
       " 'cerebrospinal',\n",
       " 'mandua',\n",
       " 'reproachableness',\n",
       " 'unissuable',\n",
       " 'porencephalous',\n",
       " 'variometer',\n",
       " 'humerodorsal',\n",
       " 'Hodgkin',\n",
       " 'unparsed',\n",
       " 'starblind',\n",
       " 'nonformation',\n",
       " 'wapentake',\n",
       " 'Acanthodei',\n",
       " 'screeny',\n",
       " 'hypoionian',\n",
       " 'greenwithe',\n",
       " 'penmaker',\n",
       " 'Eucharis',\n",
       " 'photorelief',\n",
       " 'stachydrin',\n",
       " 'demilitarize',\n",
       " 'emendate',\n",
       " 'pediluvium',\n",
       " 'Leptocardia',\n",
       " 'heliometrically',\n",
       " 'microphysiography',\n",
       " 'canephor',\n",
       " 'Cochlospermaceae',\n",
       " 'mosasaurid',\n",
       " 'perikaryon',\n",
       " 'undergrade',\n",
       " 'barrage',\n",
       " 'dilutee',\n",
       " 'closemouthed',\n",
       " 'hogweed',\n",
       " 'Amahuaca',\n",
       " 'Crocus',\n",
       " 'nongrain',\n",
       " 'hierolatry',\n",
       " 'biopsy',\n",
       " 'palpitation',\n",
       " 'chromatometer',\n",
       " 'limnologist',\n",
       " 'uracil',\n",
       " 'madly',\n",
       " 'melanian',\n",
       " 'correspondently',\n",
       " 'exhibitor',\n",
       " 'rewade',\n",
       " 'boglander',\n",
       " 'commemorize',\n",
       " 'misprision',\n",
       " 'counterproposal',\n",
       " 'demophil',\n",
       " 'collywest',\n",
       " 'Thiospira',\n",
       " 'chromotherapy',\n",
       " 'homodynamous',\n",
       " 'unconvincedly',\n",
       " 'unmedical',\n",
       " 'Hydroleaceae',\n",
       " 'ontogenal',\n",
       " 'gingivectomy',\n",
       " 'pseudocercaria',\n",
       " 'assumingness',\n",
       " 'tensify',\n",
       " 'imperforate',\n",
       " 'infralittoral',\n",
       " 'barkpeeling',\n",
       " 'neurotomy',\n",
       " 'newscasting',\n",
       " 'orthotropal',\n",
       " 'Seres',\n",
       " 'irreducibility',\n",
       " 'Acadia',\n",
       " 'overhonestly',\n",
       " 'linelet',\n",
       " 'puccinoid',\n",
       " 'arachin',\n",
       " 'pushover',\n",
       " 'drably',\n",
       " 'gaseosity',\n",
       " 'subloral',\n",
       " 'hydrotechny',\n",
       " 'daphnoid',\n",
       " 'oscillative',\n",
       " 'Typhonic',\n",
       " 'stumpish',\n",
       " 'seambiter',\n",
       " 'gulosity',\n",
       " 'upgrow',\n",
       " 'myosinogen',\n",
       " 'gnathostomous',\n",
       " 'coenesthesia',\n",
       " 'arrestive',\n",
       " 'flashingly',\n",
       " 'polypharmacon',\n",
       " 'Bambuseae',\n",
       " 'unconformed',\n",
       " 'cubocuneiform',\n",
       " 'exister',\n",
       " 'cranioschisis',\n",
       " 'partially',\n",
       " 'saxophone',\n",
       " 'osteoma',\n",
       " 'microsclerum',\n",
       " 'woodmancraft',\n",
       " 'affinitive',\n",
       " 'quietus',\n",
       " 'incorporate',\n",
       " 'sauropodous',\n",
       " 'exemplary',\n",
       " 'kathodic',\n",
       " 'blype',\n",
       " 'maconite',\n",
       " 'omnivorously',\n",
       " 'hypothesizer',\n",
       " 'xanthochroism',\n",
       " 'dispenditure',\n",
       " 'Siphonata',\n",
       " 'uncontemporary',\n",
       " 'disgenius',\n",
       " 'excecation',\n",
       " 'meandrine',\n",
       " 'pennatisected',\n",
       " 'findable',\n",
       " 'Billiken',\n",
       " 'collodion',\n",
       " 'cuneiform',\n",
       " 'Mesitae',\n",
       " 'allerion',\n",
       " 'scombroid',\n",
       " 'despicable',\n",
       " 'subpurchaser',\n",
       " 'nonancestral',\n",
       " 'assuage',\n",
       " 'decemvir',\n",
       " 'monoliteral',\n",
       " 'tryptase',\n",
       " 'increasement',\n",
       " 'ataxinomic',\n",
       " 'unadjacently',\n",
       " 'gentleheartedness',\n",
       " 'handwrist',\n",
       " 'noninstructional',\n",
       " 'disproportionation',\n",
       " 'cycadean',\n",
       " 'nonparticipating',\n",
       " 'unappreciative',\n",
       " 'heliometry',\n",
       " 'ionogen',\n",
       " 'pursuance',\n",
       " 'turbot',\n",
       " 'funipendulous',\n",
       " 'interquarter',\n",
       " 'untheatrical',\n",
       " 'doublet',\n",
       " 'carty',\n",
       " 'equalitarianism',\n",
       " 'superspirituality',\n",
       " 'saxcornet',\n",
       " 'unground',\n",
       " 'ahem',\n",
       " 'globulysis',\n",
       " 'rebuoyage',\n",
       " 'Thysanoptera',\n",
       " 'rearrangeable',\n",
       " 'plebicolar',\n",
       " 'decked',\n",
       " 'superfetation',\n",
       " 'pseudodiphtheritic',\n",
       " 'Austrophilism',\n",
       " 'ballata',\n",
       " 'banc',\n",
       " 'machinization',\n",
       " 'uncramped',\n",
       " 'varnishing',\n",
       " 'corium',\n",
       " 'Ephesine',\n",
       " 'Dimitry',\n",
       " 'crackbrained',\n",
       " 'siphonorhinal',\n",
       " 'Enaliornis',\n",
       " 'philatelically',\n",
       " 'Canopus',\n",
       " 'delineature',\n",
       " 'polycrotic',\n",
       " 'redpoll',\n",
       " 'scrabe',\n",
       " 'sophism',\n",
       " 'Spongospora',\n",
       " 'uninternational',\n",
       " 'springbok',\n",
       " 'gourdful',\n",
       " 'sunspot',\n",
       " 'zoolater',\n",
       " 'diaeresis',\n",
       " 'nymphae',\n",
       " 'posteriority',\n",
       " 'reactology',\n",
       " 'brabblement',\n",
       " 'filigerous',\n",
       " 'countervibration',\n",
       " 'quaternionist',\n",
       " 'maroon',\n",
       " 'restrap',\n",
       " 'toxicologically',\n",
       " 'obsequium',\n",
       " 'unaffectioned',\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa456e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry wkly comp win fa cup final tkts st may text fa receive entry questionstd txt ratetcs apply overs'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=df.message[2]\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987043c4",
   "metadata": {},
   "source": [
    "# Removing Emojis From Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4f27494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free entry wkly comp win fa cup final tkts st may text fa receive entry questionstd txt ratetcs apply overs\n"
     ]
    }
   ],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "print(emoji_pattern.sub(r'', message)) # no emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2005a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(message):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    message =  re.sub('entry','',message) \n",
    "    message =  re.sub('fa','',message) \n",
    "    message =  re.sub(r\"\\b[a-zA-Z]\\b\", \"\", message) \n",
    "    message =  re.sub(r\"\\b[a-zA-Z][a-zA-Z]\\b\", \"\", message) \n",
    "    message =  \" \".join(w \n",
    "                     for w in nltk.wordpunct_tokenize(message)\n",
    "                    if w.lower() in words)    \n",
    "    return message\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47517cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry wkly comp win fa cup final tkts st may text fa receive entry questionstd txt ratetcs apply overs'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20df9749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free win cup final may text receive apply'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the updated text\n",
    "df = pd.DataFrame(df.message.apply(round2))\n",
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cc35b",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34d6aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer() # lemmatizer\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()  # word tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "807542a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(abc):\n",
    "    return [lemmatizer.lemmatize(w,\"v\") ## v = verb   = arrest\n",
    "            for w in w_tokenizer.tokenize(abc)]  # word tokenizer  w = arresting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8071898d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free win cup final may text receive apply'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7aa92a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dont think go around though'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.message = df.message.apply(lambda x :' '.join(lemmatize_text(x)))  # text = x\n",
    "df.iloc[4,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dc9c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf44c7",
   "metadata": {},
   "source": [
    "# Strip extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d45e99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free win cup final may text receive apply'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9fd9bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free win cup final may text receive apply'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.message = df.message.str.rstrip()\n",
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6be6a",
   "metadata": {},
   "source": [
    "* Finished Data Pre-Processing or Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "377c2780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>point crazy available great world buffet cine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free win cup final may text receive apply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dun say early already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dont think go around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  point crazy available great world buffet cine ...\n",
       "1                                                lar\n",
       "2          free win cup final may text receive apply\n",
       "3                          dun say early already say\n",
       "4                        dont think go around though"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e4c8429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label\n",
       "0   ham\n",
       "1   ham\n",
       "2  spam\n",
       "3   ham\n",
       "4   ham"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=data[['label']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3359269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>point crazy available great world buffet cine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free win cup final may text receive apply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dun say early already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dont think go around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  point crazy available great world buffet cine ...\n",
       "1                                                lar\n",
       "2          free win cup final may text receive apply\n",
       "3                          dun say early already say\n",
       "4                        dont think go around though"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df[['message']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3097cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc2f7229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>point crazy available great world buffet cine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>lar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free win cup final may text receive apply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>dun say early already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>dont think go around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  point crazy available great world buffet cine ...\n",
       "1   ham                                                lar\n",
       "2  spam          free win cup final may text receive apply\n",
       "3   ham                          dun say early already say\n",
       "4   ham                        dont think go around though"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d89bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f4491b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>point crazy available great world buffet cine ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>lar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free win cup final may text receive apply</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>dun say early already say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>dont think go around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  point crazy available great world buffet cine ...          0\n",
       "1   ham                                                lar          0\n",
       "2  spam          free win cup final may text receive apply          1\n",
       "3   ham                          dun say early already say          0\n",
       "4   ham                        dont think go around though          0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label_num']=data.label.map({'ham':0,'spam':1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d07aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing data into train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from random import seed\n",
    "\n",
    "#seed(20)\n",
    "x = data.message\n",
    "y = data.label_num\n",
    "\n",
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(x,y,test_size=0.3,random_state=231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036d840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43ca652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "#converting features into numeric vector\n",
    "X_train = vect.fit_transform(X_train)\n",
    "#converting target into numeric vector\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1d101fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading all classifier\n",
    "svc = SVC(kernel = 'linear')\n",
    "mnb = MultinomialNB(alpha =0.2)\n",
    "gnb  = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier(n_estimators=100,random_state=11)\n",
    "abc = AdaBoostClassifier(n_estimators =100,random_state=11)\n",
    "\n",
    "model = {\n",
    "    'SVC' : svc,\n",
    "    'MNB': mnb, \n",
    "    'GNB': gnb,\n",
    "    'LR': lr, \n",
    "    'RF': rfc, \n",
    "    'AdaBoost': abc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d42ae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions for training and testing data\n",
    "\n",
    "def training(model,x_train,Y_train):\n",
    "    model.fit(x_train,Y_train)\n",
    "    \n",
    "#function for predicting labels\n",
    "\n",
    "def predict(model,X_test):\n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "098ba274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a dictionary of classifier\n",
    "classifier={'SVM': svc , 'MultinomialNB': mnb,'GaussianNB': gnb,'logistic': lr,'RandomForest': rfc,'Adaboost': abc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "578d9dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNB</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GNB</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Accuracy\n",
       "0       SVC      97.0\n",
       "1       MNB      97.0\n",
       "2       GNB      75.0\n",
       "3        LR      97.0\n",
       "4        RF      96.0\n",
       "5  AdaBoost      97.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict and storing score of each classifier\n",
    "score =[]\n",
    "for n,c in classifier.items():\n",
    "    training(c,X_train.toarray(),y_train)\n",
    "    pred = predict(c,X_test.toarray())\n",
    "    score.append((accuracy_score(y_test,pred,normalize=True)))\n",
    "performance_df = pd.DataFrame({'Algorithm':model.keys(),'Accuracy':np.round(score,2)*100})\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324804e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
